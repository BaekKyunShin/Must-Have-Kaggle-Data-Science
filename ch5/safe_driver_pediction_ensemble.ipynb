{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:36:56.076701Z",
     "iopub.status.busy": "2021-02-20T08:36:56.075925Z",
     "iopub.status.idle": "2021-02-20T08:37:06.653824Z",
     "shell.execute_reply": "2021-02-20T08:37:06.654325Z"
    },
    "papermill": {
     "duration": 10.596445,
     "end_time": "2021-02-20T08:37:06.654708",
     "exception": false,
     "start_time": "2021-02-20T08:36:56.058263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ch5/safe_driver_prediction_ensemble.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
    "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:37:06.687268Z",
     "iopub.status.busy": "2021-02-20T08:37:06.686565Z",
     "iopub.status.idle": "2021-02-20T08:37:08.031753Z",
     "shell.execute_reply": "2021-02-20T08:37:08.032465Z"
    },
    "papermill": {
     "duration": 1.363783,
     "end_time": "2021-02-20T08:37:08.032683",
     "exception": false,
     "start_time": "2021-02-20T08:37:06.668900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test], ignore_index=True)\n",
    "all_data = all_data.drop('target', axis=1) # 타깃 값 제거\n",
    "\n",
    "all_features = all_data.columns.tolist() # 전체 피처"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013594,
     "end_time": "2021-02-20T08:37:08.061168",
     "exception": false,
     "start_time": "2021-02-20T08:37:08.047574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 결측값 개수를 파생 변수로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:37:08.098509Z",
     "iopub.status.busy": "2021-02-20T08:37:08.096727Z",
     "iopub.status.idle": "2021-02-20T08:37:08.368450Z",
     "shell.execute_reply": "2021-02-20T08:37:08.369100Z"
    },
    "papermill": {
     "duration": 0.293449,
     "end_time": "2021-02-20T08:37:08.369315",
     "exception": false,
     "start_time": "2021-02-20T08:37:08.075866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '데이터 하나당 결측값 개수'를 파생 변수로 추가\n",
    "all_data['num_missing'] = (all_data==-1).sum(axis=1)\n",
    "\n",
    "# 명목형 피처, 태그에 calc가 달린 피처를 제외한 피처\n",
    "remaining_features = [col for col in all_features \\\n",
    "                      if ('cat' not in col and 'calc' not in col)] \n",
    "# num_missing을 remaining_features에 추가\n",
    "remaining_features.append('num_missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014643,
     "end_time": "2021-02-20T08:37:08.398934",
     "exception": false,
     "start_time": "2021-02-20T08:37:08.384291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 명목형 피처 원-핫 인코딩 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:37:08.432484Z",
     "iopub.status.busy": "2021-02-20T08:37:08.431552Z",
     "iopub.status.idle": "2021-02-20T08:37:12.139985Z",
     "shell.execute_reply": "2021-02-20T08:37:12.139211Z"
    },
    "papermill": {
     "duration": 3.727478,
     "end_time": "2021-02-20T08:37:12.140143",
     "exception": false,
     "start_time": "2021-02-20T08:37:08.412665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_features = [col for col in all_features if 'cat' in col] # 명목형 피처\n",
    "\n",
    "# 원-핫 인코딩 적용\n",
    "onehot_encoder = OneHotEncoder()\n",
    "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014186,
     "end_time": "2021-02-20T08:37:12.169553",
     "exception": false,
     "start_time": "2021-02-20T08:37:12.155367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `ind` 변수의 고유값을 조합한 파생 변수 `mix_ind` 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:37:12.205856Z",
     "iopub.status.busy": "2021-02-20T08:37:12.205111Z",
     "iopub.status.idle": "2021-02-20T08:37:54.885390Z",
     "shell.execute_reply": "2021-02-20T08:37:54.885975Z"
    },
    "papermill": {
     "duration": 42.702373,
     "end_time": "2021-02-20T08:37:54.886213",
     "exception": false,
     "start_time": "2021-02-20T08:37:12.183840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 태그에 ind가 달린 피처\n",
    "ind_features = [col for col in all_features if 'ind' in col]\n",
    "\n",
    "first_col=True\n",
    "for col in ind_features:\n",
    "    if first_col:\n",
    "        all_data['mix_ind'] = all_data[col].astype(str)+'_'\n",
    "        first_col = False\n",
    "    else:\n",
    "        all_data['mix_ind'] += all_data[col].astype(str)+'_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:37:54.920741Z",
     "iopub.status.busy": "2021-02-20T08:37:54.920013Z",
     "iopub.status.idle": "2021-02-20T08:38:10.055360Z",
     "shell.execute_reply": "2021-02-20T08:38:10.054547Z"
    },
    "papermill": {
     "duration": 15.154742,
     "end_time": "2021-02-20T08:38:10.055521",
     "exception": false,
     "start_time": "2021-02-20T08:37:54.900779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_count_features = []\n",
    "for col in cat_features+['mix_ind']:\n",
    "    val_counts_dic = all_data[col].value_counts().to_dict()\n",
    "    all_data[f'{col}_count'] = all_data[col].apply(lambda x: val_counts_dic[x])\n",
    "    cat_count_features.append(f'{col}_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:38:10.093036Z",
     "iopub.status.busy": "2021-02-20T08:38:10.091571Z",
     "iopub.status.idle": "2021-02-20T08:38:15.740545Z",
     "shell.execute_reply": "2021-02-20T08:38:15.740023Z"
    },
    "papermill": {
     "duration": 5.67067,
     "end_time": "2021-02-20T08:38:15.740734",
     "exception": false,
     "start_time": "2021-02-20T08:38:10.070064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "drop_features = ['ps_ind_14', 'ps_ind_10_bin','ps_ind_11_bin', \n",
    "                 'ps_ind_12_bin','ps_ind_13_bin','ps_car_14']\n",
    "\n",
    "# remaining_features, cat_count_features에서 drop_features를 제거한 데이터\n",
    "all_data_remaining = all_data[remaining_features+cat_count_features].drop(drop_features, axis=1)\n",
    "\n",
    "# 데이터 합치기\n",
    "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining),\n",
    "                               encoded_cat_matrix],\n",
    "                              format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:38:15.774901Z",
     "iopub.status.busy": "2021-02-20T08:38:15.774144Z",
     "iopub.status.idle": "2021-02-20T08:38:16.787157Z",
     "shell.execute_reply": "2021-02-20T08:38:16.786545Z"
    },
    "papermill": {
     "duration": 1.032116,
     "end_time": "2021-02-20T08:38:16.787312",
     "exception": false,
     "start_time": "2021-02-20T08:38:15.755196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_train = train.shape[0] # 훈련 데이터 개수\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터 나누기\n",
    "X = all_data_sprs[:num_train]\n",
    "X_test = all_data_sprs[num_train:]\n",
    "\n",
    "y = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:38:16.826735Z",
     "iopub.status.busy": "2021-02-20T08:38:16.825841Z",
     "iopub.status.idle": "2021-02-20T08:38:16.827456Z",
     "shell.execute_reply": "2021-02-20T08:38:16.827976Z"
    },
    "papermill": {
     "duration": 0.026179,
     "end_time": "2021-02-20T08:38:16.828147",
     "exception": false,
     "start_time": "2021-02-20T08:38:16.801968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_gini(y_true, y_pred):\n",
    "    # 실제 값과 예측 값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n",
    "    assert y_true.shape == y_pred.shape\n",
    "\n",
    "    n_samples = y_true.shape[0] # 데이터 개수\n",
    "    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n",
    "\n",
    "    # 1) 예측 값에 대한 지니계수\n",
    "    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n",
    "    G_pred = np.sum(L_mid - L_pred)# 예측 값에 대한 지니계수\n",
    "\n",
    "    # 2) 예측이 완벽할 때 지니계수\n",
    "    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n",
    "    G_true = np.sum(L_mid - L_true) # 예측이 완벽할 때 지니계수\n",
    "\n",
    "    # 정규화된 지니계수\n",
    "    return G_pred / G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:38:16.861808Z",
     "iopub.status.busy": "2021-02-20T08:38:16.861004Z",
     "iopub.status.idle": "2021-02-20T08:38:16.865928Z",
     "shell.execute_reply": "2021-02-20T08:38:16.866450Z"
    },
    "papermill": {
     "duration": 0.023604,
     "end_time": "2021-02-20T08:38:16.866648",
     "exception": false,
     "start_time": "2021-02-20T08:38:16.843044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gini_lgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', eval_gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:38:16.902939Z",
     "iopub.status.busy": "2021-02-20T08:38:16.902222Z",
     "iopub.status.idle": "2021-02-20T08:38:16.905660Z",
     "shell.execute_reply": "2021-02-20T08:38:16.905133Z"
    },
    "papermill": {
     "duration": 0.023351,
     "end_time": "2021-02-20T08:38:16.905818",
     "exception": false,
     "start_time": "2021-02-20T08:38:16.882467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', eval_gini(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:38:16.942291Z",
     "iopub.status.busy": "2021-02-20T08:38:16.941581Z",
     "iopub.status.idle": "2021-02-20T08:38:17.008113Z",
     "shell.execute_reply": "2021-02-20T08:38:17.006214Z"
    },
    "papermill": {
     "duration": 0.08633,
     "end_time": "2021-02-20T08:38:17.008302",
     "exception": false,
     "start_time": "2021-02-20T08:38:16.921972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Stratified K 폴드 교차검증기 생성\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:38:17.046784Z",
     "iopub.status.busy": "2021-02-20T08:38:17.046115Z",
     "iopub.status.idle": "2021-02-20T08:38:17.049256Z",
     "shell.execute_reply": "2021-02-20T08:38:17.048544Z"
    },
    "papermill": {
     "duration": 0.024886,
     "end_time": "2021-02-20T08:38:17.049406",
     "exception": false,
     "start_time": "2021-02-20T08:38:17.024520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_params_lgb = {'bagging_fraction': 0.8043696643500143,\n",
    " 'feature_fraction': 0.6829323879981047,\n",
    " 'lambda_l1': 0.9264555612104627,\n",
    " 'lambda_l2': 0.9774233689434216,\n",
    " 'min_child_samples': 10,\n",
    " 'min_child_weight': 125.68433948868649,\n",
    " 'num_leaves': 28,\n",
    " 'objective': 'binary',\n",
    " 'learning_rate': 0.01,\n",
    " 'bagging_freq': 1,\n",
    " 'verbosity': 0,\n",
    " 'random_state': 1991}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:38:17.092277Z",
     "iopub.status.busy": "2021-02-20T08:38:17.089703Z",
     "iopub.status.idle": "2021-02-20T08:52:03.418821Z",
     "shell.execute_reply": "2021-02-20T08:52:03.419441Z"
    },
    "papermill": {
     "duration": 826.355414,
     "end_time": "2021-02-20T08:52:03.419887",
     "exception": false,
     "start_time": "2021-02-20T08:38:17.064473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Fold 1 out of 5 ########################################\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153315\tvalid_0's gini: 0.270034\n",
      "[200]\tvalid_0's binary_logloss: 0.152339\tvalid_0's gini: 0.280485\n",
      "[300]\tvalid_0's binary_logloss: 0.151922\tvalid_0's gini: 0.286543\n",
      "[400]\tvalid_0's binary_logloss: 0.15169\tvalid_0's gini: 0.291089\n",
      "[500]\tvalid_0's binary_logloss: 0.151544\tvalid_0's gini: 0.294535\n",
      "[600]\tvalid_0's binary_logloss: 0.151467\tvalid_0's gini: 0.296222\n",
      "[700]\tvalid_0's binary_logloss: 0.151405\tvalid_0's gini: 0.297658\n",
      "[800]\tvalid_0's binary_logloss: 0.151368\tvalid_0's gini: 0.298591\n",
      "[900]\tvalid_0's binary_logloss: 0.151337\tvalid_0's gini: 0.299329\n",
      "[1000]\tvalid_0's binary_logloss: 0.151325\tvalid_0's gini: 0.299571\n",
      "[1100]\tvalid_0's binary_logloss: 0.151312\tvalid_0's gini: 0.29987\n",
      "[1200]\tvalid_0's binary_logloss: 0.151309\tvalid_0's gini: 0.299973\n",
      "[1300]\tvalid_0's binary_logloss: 0.151309\tvalid_0's gini: 0.29986\n",
      "Early stopping, best iteration is:\n",
      "[1209]\tvalid_0's binary_logloss: 0.151306\tvalid_0's gini: 0.300053\n",
      "Fold 1 gini score: 0.3000525641260156\n",
      "\n",
      "######################################## Fold 2 out of 5 ########################################\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153498\tvalid_0's gini: 0.258413\n",
      "[200]\tvalid_0's binary_logloss: 0.15262\tvalid_0's gini: 0.26765\n",
      "[300]\tvalid_0's binary_logloss: 0.152267\tvalid_0's gini: 0.273355\n",
      "[400]\tvalid_0's binary_logloss: 0.152086\tvalid_0's gini: 0.277154\n",
      "[500]\tvalid_0's binary_logloss: 0.151977\tvalid_0's gini: 0.279912\n",
      "[600]\tvalid_0's binary_logloss: 0.151912\tvalid_0's gini: 0.281631\n",
      "[700]\tvalid_0's binary_logloss: 0.151872\tvalid_0's gini: 0.28274\n",
      "[800]\tvalid_0's binary_logloss: 0.151831\tvalid_0's gini: 0.283899\n",
      "[900]\tvalid_0's binary_logloss: 0.15182\tvalid_0's gini: 0.284216\n",
      "[1000]\tvalid_0's binary_logloss: 0.151807\tvalid_0's gini: 0.284581\n",
      "[1100]\tvalid_0's binary_logloss: 0.151792\tvalid_0's gini: 0.285036\n",
      "[1200]\tvalid_0's binary_logloss: 0.151792\tvalid_0's gini: 0.285047\n",
      "[1300]\tvalid_0's binary_logloss: 0.151786\tvalid_0's gini: 0.285333\n",
      "[1400]\tvalid_0's binary_logloss: 0.151787\tvalid_0's gini: 0.285537\n",
      "[1500]\tvalid_0's binary_logloss: 0.151784\tvalid_0's gini: 0.285584\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1459]\tvalid_0's binary_logloss: 0.151783\tvalid_0's gini: 0.285681\n",
      "Fold 2 gini score: 0.2856809897393425\n",
      "\n",
      "######################################## Fold 3 out of 5 ########################################\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.228709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153333\tvalid_0's gini: 0.26323\n",
      "[200]\tvalid_0's binary_logloss: 0.152367\tvalid_0's gini: 0.272493\n",
      "[300]\tvalid_0's binary_logloss: 0.151978\tvalid_0's gini: 0.277774\n",
      "[400]\tvalid_0's binary_logloss: 0.151784\tvalid_0's gini: 0.280881\n",
      "[500]\tvalid_0's binary_logloss: 0.151686\tvalid_0's gini: 0.282794\n",
      "[600]\tvalid_0's binary_logloss: 0.151638\tvalid_0's gini: 0.283821\n",
      "[700]\tvalid_0's binary_logloss: 0.151613\tvalid_0's gini: 0.284375\n",
      "[800]\tvalid_0's binary_logloss: 0.151606\tvalid_0's gini: 0.284532\n",
      "[900]\tvalid_0's binary_logloss: 0.151599\tvalid_0's gini: 0.284754\n",
      "[1000]\tvalid_0's binary_logloss: 0.151592\tvalid_0's gini: 0.284938\n",
      "[1100]\tvalid_0's binary_logloss: 0.151601\tvalid_0's gini: 0.284697\n",
      "Early stopping, best iteration is:\n",
      "[950]\tvalid_0's binary_logloss: 0.151592\tvalid_0's gini: 0.284989\n",
      "Fold 3 gini score: 0.2849885601271959\n",
      "\n",
      "######################################## Fold 4 out of 5 ########################################\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153435\tvalid_0's gini: 0.256627\n",
      "[200]\tvalid_0's binary_logloss: 0.152524\tvalid_0's gini: 0.266658\n",
      "[300]\tvalid_0's binary_logloss: 0.152191\tvalid_0's gini: 0.271067\n",
      "[400]\tvalid_0's binary_logloss: 0.152034\tvalid_0's gini: 0.27396\n",
      "[500]\tvalid_0's binary_logloss: 0.151942\tvalid_0's gini: 0.27619\n",
      "[600]\tvalid_0's binary_logloss: 0.151882\tvalid_0's gini: 0.277677\n",
      "[700]\tvalid_0's binary_logloss: 0.151851\tvalid_0's gini: 0.278579\n",
      "[800]\tvalid_0's binary_logloss: 0.151819\tvalid_0's gini: 0.279461\n",
      "[900]\tvalid_0's binary_logloss: 0.151808\tvalid_0's gini: 0.279975\n",
      "[1000]\tvalid_0's binary_logloss: 0.151798\tvalid_0's gini: 0.280149\n",
      "[1100]\tvalid_0's binary_logloss: 0.151797\tvalid_0's gini: 0.280201\n",
      "[1200]\tvalid_0's binary_logloss: 0.151797\tvalid_0's gini: 0.280353\n",
      "Early stopping, best iteration is:\n",
      "[1128]\tvalid_0's binary_logloss: 0.151791\tvalid_0's gini: 0.280389\n",
      "Fold 4 gini score: 0.2803887114157609\n",
      "\n",
      "######################################## Fold 5 out of 5 ########################################\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.153534\tvalid_0's gini: 0.265252\n",
      "[200]\tvalid_0's binary_logloss: 0.152629\tvalid_0's gini: 0.274421\n",
      "[300]\tvalid_0's binary_logloss: 0.152249\tvalid_0's gini: 0.280526\n",
      "[400]\tvalid_0's binary_logloss: 0.152031\tvalid_0's gini: 0.285706\n",
      "[500]\tvalid_0's binary_logloss: 0.151906\tvalid_0's gini: 0.289104\n",
      "[600]\tvalid_0's binary_logloss: 0.151817\tvalid_0's gini: 0.29166\n",
      "[700]\tvalid_0's binary_logloss: 0.151771\tvalid_0's gini: 0.292958\n",
      "[800]\tvalid_0's binary_logloss: 0.15174\tvalid_0's gini: 0.293975\n",
      "[900]\tvalid_0's binary_logloss: 0.151721\tvalid_0's gini: 0.294603\n",
      "[1000]\tvalid_0's binary_logloss: 0.151709\tvalid_0's gini: 0.295097\n",
      "[1100]\tvalid_0's binary_logloss: 0.151689\tvalid_0's gini: 0.295655\n",
      "[1200]\tvalid_0's binary_logloss: 0.151685\tvalid_0's gini: 0.295904\n",
      "[1300]\tvalid_0's binary_logloss: 0.151685\tvalid_0's gini: 0.295988\n",
      "[1400]\tvalid_0's binary_logloss: 0.151683\tvalid_0's gini: 0.296066\n",
      "Early stopping, best iteration is:\n",
      "[1321]\tvalid_0's binary_logloss: 0.151681\tvalid_0's gini: 0.296151\n",
      "Fold 5 gini score: 0.2961510502799241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃 값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds_lgb = np.zeros(X.shape[0]) \n",
    "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃 값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds_lgb = np.zeros(X_test.shape[0]) \n",
    "\n",
    "# OOF 방식으로 모델 훈련, 검증, 예측\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    # 각 폴드를 구분하는 문구\n",
    "    print('#'*40, f'Fold {idx+1} out of {folds.n_splits}', '#'*40)\n",
    "    \n",
    "    # 훈련용 데이터, 검증용 데이터 설정 ---①\n",
    "    X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n",
    "    X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n",
    "\n",
    "    # lgbm 데이터세트 생성 ---②\n",
    "    dtrain = lgbm.Dataset(X_train, y_train) # lgbm 훈련 데이터세트\n",
    "    dvalid = lgbm.Dataset(X_valid, y_valid) # lgbm 검증 데이터세트\n",
    "\n",
    "    # Light GBM 모델 훈련 ---③\n",
    "    lgb_model = lgbm.train(params=max_params_lgb, # 최적 하이퍼 파라미터\n",
    "                           train_set=dtrain, # 훈련 데이터\n",
    "                           num_boost_round=1500, # 부스팅 반복 횟수\n",
    "                           valid_sets=dvalid, # 모델 성능 평가용 검증 데이터\n",
    "                           feval=gini_lgb, # 검증용 평가지표\n",
    "                           early_stopping_rounds=150, # 조기종료 조건\n",
    "                           verbose_eval=100)\n",
    "    \n",
    "    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장 ---④\n",
    "    best_iter = lgb_model.best_iteration\n",
    "    # 테스트 데이터를 활용해 예측 ---⑤\n",
    "    oof_test_preds_lgb += lgb_model.predict(X_test, \n",
    "                                    num_iteration=best_iter)/folds.n_splits\n",
    "    # 모델 성능 평가를 위한 oof 예측 ---⑥\n",
    "    oof_val_preds_lgb[valid_idx] += lgb_model.predict(X_valid, num_iteration=best_iter)\n",
    "    \n",
    "    # oof 예측확률에 대한 정규화 지니계수 ---⑦\n",
    "    gini_score = eval_gini(y_valid, oof_val_preds_lgb[valid_idx])\n",
    "    print(f'Fold {idx+1} gini score: {gini_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:52:03.507422Z",
     "iopub.status.busy": "2021-02-20T08:52:03.506580Z",
     "iopub.status.idle": "2021-02-20T08:52:03.512061Z",
     "shell.execute_reply": "2021-02-20T08:52:03.512690Z"
    },
    "papermill": {
     "duration": 0.051728,
     "end_time": "2021-02-20T08:52:03.512879",
     "exception": false,
     "start_time": "2021-02-20T08:52:03.461151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_params_xgb = {'colsample_bytree': 0.8927325521002059,\n",
    " 'gamma': 9.766883037651555,\n",
    " 'max_depth': 7,\n",
    " 'min_child_weight': 6.0577898395058085,\n",
    " 'reg_alpha': 8.136089122187865,\n",
    " 'reg_lambda': 1.385119327658532,\n",
    " 'scale_pos_weight': 1.5142072116395773,\n",
    " 'subsample': 0.717425859940308,\n",
    " 'objective': 'binary:logistic',\n",
    " 'learning_rate': 0.05,\n",
    " 'random_state': 1991}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T08:52:03.602185Z",
     "iopub.status.busy": "2021-02-20T08:52:03.601432Z",
     "iopub.status.idle": "2021-02-20T09:36:38.021245Z",
     "shell.execute_reply": "2021-02-20T09:36:38.021747Z"
    },
    "papermill": {
     "duration": 2674.466895,
     "end_time": "2021-02-20T09:36:38.022135",
     "exception": false,
     "start_time": "2021-02-20T08:52:03.555240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Fold 1 out of 5 ########################################\n",
      "[08:52:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.65258\ttrain-gini:0.15851\tvalid-logloss:0.65282\tvalid-gini:0.15941\n",
      "[100]\ttrain-logloss:0.15549\ttrain-gini:0.30907\tvalid-logloss:0.15637\tvalid-gini:0.28555\n",
      "[200]\ttrain-logloss:0.15314\ttrain-gini:0.33829\tvalid-logloss:0.15485\tvalid-gini:0.29589\n",
      "[300]\ttrain-logloss:0.15240\ttrain-gini:0.35689\tvalid-logloss:0.15475\tvalid-gini:0.29885\n",
      "[400]\ttrain-logloss:0.15174\ttrain-gini:0.37316\tvalid-logloss:0.15474\tvalid-gini:0.29912\n",
      "[500]\ttrain-logloss:0.15119\ttrain-gini:0.38594\tvalid-logloss:0.15473\tvalid-gini:0.29909\n",
      "[600]\ttrain-logloss:0.15069\ttrain-gini:0.39837\tvalid-logloss:0.15473\tvalid-gini:0.29956\n",
      "[700]\ttrain-logloss:0.15024\ttrain-gini:0.40826\tvalid-logloss:0.15475\tvalid-gini:0.29816\n",
      "[756]\ttrain-logloss:0.15005\ttrain-gini:0.41341\tvalid-logloss:0.15482\tvalid-gini:0.29697\n",
      "Fold 1 gini score: 0.29961440115120136\n",
      "\n",
      "######################################## Fold 2 out of 5 ########################################\n",
      "[09:03:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.65280\ttrain-gini:0.17041\tvalid-logloss:0.65286\tvalid-gini:0.15070\n",
      "[100]\ttrain-logloss:0.15533\ttrain-gini:0.31502\tvalid-logloss:0.15672\tvalid-gini:0.27012\n",
      "[200]\ttrain-logloss:0.15294\ttrain-gini:0.34420\tvalid-logloss:0.15526\tvalid-gini:0.28048\n",
      "[300]\ttrain-logloss:0.15219\ttrain-gini:0.36305\tvalid-logloss:0.15516\tvalid-gini:0.28315\n",
      "[400]\ttrain-logloss:0.15157\ttrain-gini:0.37753\tvalid-logloss:0.15518\tvalid-gini:0.28335\n",
      "[500]\ttrain-logloss:0.15099\ttrain-gini:0.39024\tvalid-logloss:0.15515\tvalid-gini:0.28363\n",
      "[600]\ttrain-logloss:0.15056\ttrain-gini:0.40046\tvalid-logloss:0.15516\tvalid-gini:0.28372\n",
      "[601]\ttrain-logloss:0.15054\ttrain-gini:0.40046\tvalid-logloss:0.15515\tvalid-gini:0.28372\n",
      "Fold 2 gini score: 0.2837606145329253\n",
      "\n",
      "######################################## Fold 3 out of 5 ########################################\n",
      "[09:12:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.65262\ttrain-gini:0.15709\tvalid-logloss:0.65285\tvalid-gini:0.15487\n",
      "[100]\ttrain-logloss:0.15544\ttrain-gini:0.31322\tvalid-logloss:0.15642\tvalid-gini:0.27724\n",
      "[200]\ttrain-logloss:0.15295\ttrain-gini:0.34562\tvalid-logloss:0.15502\tvalid-gini:0.28340\n",
      "[300]\ttrain-logloss:0.15217\ttrain-gini:0.36375\tvalid-logloss:0.15495\tvalid-gini:0.28432\n",
      "[400]\ttrain-logloss:0.15160\ttrain-gini:0.37817\tvalid-logloss:0.15495\tvalid-gini:0.28408\n",
      "[456]\ttrain-logloss:0.15129\ttrain-gini:0.38554\tvalid-logloss:0.15496\tvalid-gini:0.28366\n",
      "Fold 3 gini score: 0.2845216377812854\n",
      "\n",
      "######################################## Fold 4 out of 5 ########################################\n",
      "[09:19:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.65271\ttrain-gini:0.16650\tvalid-logloss:0.65277\tvalid-gini:0.17177\n",
      "[100]\ttrain-logloss:0.15527\ttrain-gini:0.31558\tvalid-logloss:0.15657\tvalid-gini:0.26864\n",
      "[200]\ttrain-logloss:0.15291\ttrain-gini:0.34497\tvalid-logloss:0.15521\tvalid-gini:0.27653\n",
      "[300]\ttrain-logloss:0.15224\ttrain-gini:0.36147\tvalid-logloss:0.15518\tvalid-gini:0.27765\n",
      "[400]\ttrain-logloss:0.15164\ttrain-gini:0.37543\tvalid-logloss:0.15515\tvalid-gini:0.27805\n",
      "[500]\ttrain-logloss:0.15113\ttrain-gini:0.38817\tvalid-logloss:0.15520\tvalid-gini:0.27706\n",
      "[567]\ttrain-logloss:0.15085\ttrain-gini:0.39455\tvalid-logloss:0.15521\tvalid-gini:0.27701\n",
      "Fold 4 gini score: 0.27816885974665556\n",
      "\n",
      "######################################## Fold 5 out of 5 ########################################\n",
      "[09:27:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.65292\ttrain-gini:0.16864\tvalid-logloss:0.65280\tvalid-gini:0.16969\n",
      "[100]\ttrain-logloss:0.15538\ttrain-gini:0.30959\tvalid-logloss:0.15661\tvalid-gini:0.28038\n",
      "[200]\ttrain-logloss:0.15299\ttrain-gini:0.34050\tvalid-logloss:0.15515\tvalid-gini:0.29119\n",
      "[300]\ttrain-logloss:0.15226\ttrain-gini:0.35818\tvalid-logloss:0.15500\tvalid-gini:0.29510\n",
      "[400]\ttrain-logloss:0.15171\ttrain-gini:0.37128\tvalid-logloss:0.15495\tvalid-gini:0.29606\n",
      "[500]\ttrain-logloss:0.15115\ttrain-gini:0.38453\tvalid-logloss:0.15491\tvalid-gini:0.29648\n",
      "[600]\ttrain-logloss:0.15069\ttrain-gini:0.39609\tvalid-logloss:0.15491\tvalid-gini:0.29647\n",
      "[675]\ttrain-logloss:0.15033\ttrain-gini:0.40357\tvalid-logloss:0.15491\tvalid-gini:0.29615\n",
      "Fold 5 gini score: 0.2966429888208315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃 값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds_xgb = np.zeros(X.shape[0]) \n",
    "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃 값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds_xgb = np.zeros(X_test.shape[0]) \n",
    "\n",
    "# OOF 방식으로 모델 훈련, 검증, 예측\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    # 각 폴드를 구분하는 문구\n",
    "    print('#'*40, f'Fold {idx+1} out of {folds.n_splits}', '#'*40)\n",
    "    \n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "    # xgb 데이터세트 생성 \n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    \n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "    xgb_model = xgb.train(params=max_params_xgb, \n",
    "                           dtrain=dtrain,\n",
    "                           num_boost_round=1000,\n",
    "                           evals=watchlist,\n",
    "                          maximize=True,\n",
    "                           feval=gini_xgb,\n",
    "                           early_stopping_rounds=150,\n",
    "                           verbose_eval=100)\n",
    "\n",
    "    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장\n",
    "    best_iter = xgb_model.best_iteration\n",
    "    # 테스트 데이터를 활용해 예측\n",
    "    oof_test_preds_xgb += xgb_model.predict(dtest, \n",
    "                                    ntree_limit=best_iter)/folds.n_splits\n",
    "    # 모델 성능 평가를 위한 oof 예측 ---⑥\n",
    "    oof_val_preds_xgb[valid_idx] += xgb_model.predict(dvalid, ntree_limit=best_iter)\n",
    "    \n",
    "    # oof 예측확률에 대한 정규화 지니계수 ---⑦\n",
    "    gini_score = eval_gini(y_valid, oof_val_preds_xgb[valid_idx])\n",
    "    print(f'Fold {idx+1} gini score: {gini_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T09:36:38.141264Z",
     "iopub.status.busy": "2021-02-20T09:36:38.140485Z",
     "iopub.status.idle": "2021-02-20T09:36:38.259458Z",
     "shell.execute_reply": "2021-02-20T09:36:38.259993Z"
    },
    "papermill": {
     "duration": 0.183224,
     "end_time": "2021-02-20T09:36:38.260190",
     "exception": false,
     "start_time": "2021-02-20T09:36:38.076966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM OOF Gini Score: 0.2893420267793303\n"
     ]
    }
   ],
   "source": [
    "print('LightGBM OOF Gini Score:', eval_gini(y, oof_val_preds_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T09:36:38.376023Z",
     "iopub.status.busy": "2021-02-20T09:36:38.375318Z",
     "iopub.status.idle": "2021-02-20T09:36:38.484020Z",
     "shell.execute_reply": "2021-02-20T09:36:38.483421Z"
    },
    "papermill": {
     "duration": 0.16858,
     "end_time": "2021-02-20T09:36:38.484167",
     "exception": false,
     "start_time": "2021-02-20T09:36:38.315587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost OOF Gini Score: 0.28849001909297844\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost OOF Gini Score:', eval_gini(y, oof_val_preds_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T09:36:38.604783Z",
     "iopub.status.busy": "2021-02-20T09:36:38.604021Z",
     "iopub.status.idle": "2021-02-20T09:36:42.321720Z",
     "shell.execute_reply": "2021-02-20T09:36:42.321039Z"
    },
    "papermill": {
     "duration": 3.780858,
     "end_time": "2021-02-20T09:36:42.321882",
     "exception": false,
     "start_time": "2021-02-20T09:36:38.541024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_test_preds = oof_test_preds_lgb * 0.6 + oof_test_preds_xgb * 0.4\n",
    "submission['target'] = oof_test_preds\n",
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3593.587835,
   "end_time": "2021-02-20T09:36:43.394143",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-20T08:36:49.806308",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
